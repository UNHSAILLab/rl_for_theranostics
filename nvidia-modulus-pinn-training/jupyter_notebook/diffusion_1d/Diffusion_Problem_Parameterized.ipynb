{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameterizing the PDE\n",
    "\n",
    "As we discussed earlier, one important advantage of a PINN solver over traditional numerical methods is its ability to solve parameterized geometries and PDEs. This was initially proposed in the [paper](https://arxiv.org/abs/1906.02382) published by Sun et al. This allows us significant computational advantage, as one can now use PINNs to solve for multiple designs/cases in a single training. Once the training is complete, it is possible to run inference on several geometry/physical parameter combinations as a post-processing step, without solving the forward problem again. \n",
    "\n",
    "To demonstrate the concept, we will train the same 1D diffusion problem, but now by parameterizing the conductivity of the first bar in the range (5, 25). Once the training is complete, we can obtain the results for any conductivity value in that range saving us the time to train multiple models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Setup\n",
    "\n",
    "The definition of equations remains the same for this part. Since earlier while defining the equations, we already defined the constants and coefficients of the PDE to be either numerical values or strings, this will allow us to parameterize `D1` by passing it as a string while calling the equations and making the neural network. Now let's start by creating the parameterized train domain. We will skip the parts that are common to the previous section and only discuss the changes. The complete script can be referred in [`diffusion_bar_parameterized.py`](../../source_code/diffusion_1d/diffusion_bar_parameterized.py). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Parameterized PDE and Neural Network Nodes\n",
    "\n",
    "Before starting out to create the nodes and domain, we will create the symbolic variable for the $D_1$ and also specify the range of variation for the variable. While the simulation runs, we will validate it against the same diffusion coefficient that we solved earlier i.e. $D_1=10$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# params for domain\n",
    "L1 = Line1D(0, 1)\n",
    "L2 = Line1D(1, 2)\n",
    "\n",
    "D1 = Symbol(\"D1\")\n",
    "D1_range = {D1: (5, 25)}\n",
    "D1_validation = 1e1\n",
    "\n",
    "D2 = 1e-1\n",
    "\n",
    "Tc = 100\n",
    "Ta = 0\n",
    "Tb = (Tc + (D1 / D2) * Ta) / (1 + (D1 / D2))\n",
    "Tb_validation = float(Tb.evalf(subs={D1: 1e1}))\n",
    "\n",
    "print(Ta)\n",
    "print(Tb)\n",
    "print(Tc)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the parameterized model, we will have the symbolic parameters we just defined as inputs to both the neural networks in `diff_net_u_1` and `diff_net_u_2` viz. `'D1'` along with the usual x coordinate. The outputs remain the same as what we would have for any other non-parameterized simulation. This way the network learns a function that has both `'x'` and `'D1'` as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@modulus.main(config_path=\"conf\", config_name=\"config_param\")\n",
    "def run(cfg: ModulusConfig) -> None:\n",
    "    # make list of nodes to unroll graph on\n",
    "    diff_u1 = Diffusion(T=\"u_1\", D=\"D1\", dim=1, time=False)\n",
    "    diff_u2 = Diffusion(T=\"u_2\", D=D2, dim=1, time=False)\n",
    "    diff_in = DiffusionInterface(\"u_1\", \"u_2\", \"D1\", D2, dim=1, time=False)\n",
    "\n",
    "    diff_net_u_1 = instantiate_arch(\n",
    "        input_keys=[Key(\"x\"), Key(\"D1\")],\n",
    "        output_keys=[Key(\"u_1\")],\n",
    "        cfg=cfg.arch.fully_connected,\n",
    "    )\n",
    "    diff_net_u_2 = instantiate_arch(\n",
    "        input_keys=[Key(\"x\"), Key(\"D1\")],\n",
    "        output_keys=[Key(\"u_2\")],\n",
    "        cfg=cfg.arch.fully_connected,\n",
    "    )\n",
    "\n",
    "    nodes = (\n",
    "        diff_u1.make_nodes()\n",
    "        + diff_u2.make_nodes()\n",
    "        + diff_in.make_nodes()\n",
    "        + [diff_net_u_1.make_node(name=\"u1_network\", jit=cfg.jit)]\n",
    "        + [diff_net_u_2.make_node(name=\"u2_network\", jit=cfg.jit)]\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Parameterized Boundary and PDE Constraints\n",
    "\n",
    "This part of the code is very similar to the non-parameterized version. The symbolic variables and the ranges that we described earlier need to be input to the `parameterization` attribute of each boundary and internal constraint (`PointwiseBoundaryConstraint` and `PointwiseInteriorConstraint`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make domain add constraints to the solver\n",
    "    domain = Domain()\n",
    "\n",
    "    # sympy variables\n",
    "    x = Symbol(\"x\")\n",
    "\n",
    "    # right hand side (x = 2) Pt c\n",
    "    rhs = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L2,\n",
    "        outvar={\"u_2\": Tc},\n",
    "        batch_size=cfg.batch_size.rhs,\n",
    "        criteria=Eq(x, 2),\n",
    "        parameterization=Parameterization(D1_range),\n",
    "    )\n",
    "    domain.add_constraint(rhs, \"right_hand_side\")\n",
    "\n",
    "    # left hand side (x = 0) Pt a\n",
    "    lhs = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L1,\n",
    "        outvar={\"u_1\": Ta},\n",
    "        batch_size=cfg.batch_size.lhs,\n",
    "        criteria=Eq(x, 0),\n",
    "        parameterization=Parameterization(D1_range),\n",
    "    )\n",
    "    domain.add_constraint(lhs, \"left_hand_side\")\n",
    "\n",
    "    # interface 1-2\n",
    "    interface = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L1,\n",
    "        outvar={\n",
    "            \"diffusion_interface_dirichlet_u_1_u_2\": 0,\n",
    "            \"diffusion_interface_neumann_u_1_u_2\": 0,\n",
    "        },\n",
    "        batch_size=cfg.batch_size.interface,\n",
    "        criteria=Eq(x, 1),\n",
    "        parameterization=Parameterization(D1_range),\n",
    "    )\n",
    "    domain.add_constraint(interface, \"interface\")\n",
    "\n",
    "    # interior 1\n",
    "    interior_u1 = PointwiseInteriorConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L1,\n",
    "        outvar={\"diffusion_u_1\": 0},\n",
    "        bounds={x: (0, 1)},\n",
    "        batch_size=cfg.batch_size.interior_u1,\n",
    "        parameterization=Parameterization(D1_range),\n",
    "    )\n",
    "    domain.add_constraint(interior_u1, \"interior_u1\")\n",
    "\n",
    "    # interior 2\n",
    "    interior_u2 = PointwiseInteriorConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L2,\n",
    "        outvar={\"diffusion_u_2\": 0},\n",
    "        bounds={x: (1, 2)},\n",
    "        batch_size=cfg.batch_size.interior_u2,\n",
    "        parameterization=Parameterization(D1_range),\n",
    "    )\n",
    "    domain.add_constraint(interior_u2, \"interior_u2\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Validators and Monitors \n",
    "\n",
    "The process to create these domains is again similar to the previous section. For validation data, we need to create an additional key for the string `'D1'` in the `invar_numpy` dictionary. The value for this key can be in the range we specified earlier and which we would like to validate against. It is possible to create multiple validators if required, e.g. different $D_1$ values. For the monitor domain, a similar `invar_numpy` is generated that has both the `'x'` and `'D1'` keys as well as the appropriate arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # validation data\n",
    "    x = np.expand_dims(np.linspace(0, 1, 100), axis=-1)\n",
    "    u_1 = x * Tb_validation + (1 - x) * Ta\n",
    "    invar_numpy = {\"x\": x}\n",
    "    invar_numpy.update({\"D1\": np.full_like(invar_numpy[\"x\"], D1_validation)})\n",
    "    outvar_numpy = {\"u_1\": u_1}\n",
    "    val = PointwiseValidator(nodes=nodes, invar=invar_numpy, true_outvar=outvar_numpy)\n",
    "    domain.add_validator(val, name=\"Val1\")\n",
    "\n",
    "    # make validation data line 2\n",
    "    x = np.expand_dims(np.linspace(1, 2, 100), axis=-1)\n",
    "    u_2 = (x - 1) * Tc + (2 - x) * Tb_validation\n",
    "    invar_numpy = {\"x\": x}\n",
    "    invar_numpy.update({\"D1\": np.full_like(invar_numpy[\"x\"], D1_validation)})\n",
    "    outvar_numpy = {\"u_2\": u_2}\n",
    "    val = PointwiseValidator(nodes=nodes, invar=invar_numpy, true_outvar=outvar_numpy)\n",
    "    domain.add_validator(val, name=\"Val2\")\n",
    "\n",
    "    # make monitors\n",
    "    invar_numpy = {\"x\": [[1.0]], \"D1\": [[D1_validation]]}\n",
    "    monitor = PointwiseMonitor(\n",
    "        invar_numpy,\n",
    "        output_names=[\"u_1__x\"],\n",
    "        metrics={\"flux_u1\": lambda var: torch.mean(var[\"u_1__x\"])},\n",
    "        nodes=nodes,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "    domain.add_monitor(monitor)\n",
    "\n",
    "    monitor = PointwiseMonitor(\n",
    "        invar_numpy,\n",
    "        output_names=[\"u_2__x\"],\n",
    "        metrics={\"flux_u2\": lambda var: torch.mean(var[\"u_2__x\"])},\n",
    "        nodes=nodes,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "    domain.add_monitor(monitor)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver and Training\n",
    "\n",
    "Now that we have the definitions for the various constraints and domains complete, we can form the solver and run the problem similar to before. The code to do the same can be found below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make solver\n",
    "    slv = Solver(cfg, domain)\n",
    "\n",
    "    # start solver\n",
    "    slv.solve()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../../source_code/diffusion_1d/diffusion_bar_parameterized.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Solution\n",
    "\n",
    "The .npz arrays can be plotted similar to previous section to visualize the output of the simulation. You can see that we get the same answer as the analytical solution. You can try to run the problem in `eval` mode by changing the validation data and see how it performs for the other `D1` values as well. To run the model in evaluation mode (i.e. without training), you just need to [modify the config file](https://docs.nvidia.com/deeplearning/modulus/text/features/configuration.html#run-modes).  \n",
    "\n",
    "<img src=\"image_diffusion_problem_bootcamp_parameterized.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "You can see that at a fractional increase in computational time, we solved the PDE for $D_1$ ranging from (5, 25). This concept can easily be extended to more complicated problems and this ability of solving parameterized problems comes in handy very much during design optimization and exploring the design space. For more examples of solving parameterized problems, please refer to [Modulus User Documentation](https://docs.nvidia.com/deeplearning/modulus/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook we will solve the system of differential equations that define a coupled spring mass problem.\n",
    "\n",
    "Please continue to [the next notebook](../spring_mass/Spring_Mass_Problem_Notebook.ipynb)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
