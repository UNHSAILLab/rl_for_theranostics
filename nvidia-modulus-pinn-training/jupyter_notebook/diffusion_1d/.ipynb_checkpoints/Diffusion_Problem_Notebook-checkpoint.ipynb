{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steady State 1D Diffusion in a Composite Bar Using PINNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will solve a diffusion PDE with PINNs and then later extend it to solve a parameterized PDE. We will see how easy it is to convert a single forward simulation to a parameterized simulation (parameterization can be for boundary conditions, PDE coefficients, geometry, etc.) using Modulus APIs. \n",
    "\n",
    "Let's quickly recap the theory of PINNs before proceeding. We will embed the physics of the problem in the neural networks and in such a setting, we can use them to approximate the solution to a given differential equation and boundary condition without any training data from other solvers. More specifically, the neural network will be trained to minimize a loss function which is formed using the differential equation and the boundary conditions. If the network is able to minimize this loss then it will in effect solve the given differential equation. More information about the Physics Informed Neural Networks (PINNs) can be found in [this paper](https://www.sciencedirect.com/science/article/pii/S0021999118307125?casa_token=1CnSbVeDwJ0AAAAA:-8a6ZMjO7RgYjFBAxIoVU2sWAdsqFzLRTNHA1BkRryNPXx5Vjc8hCDCkS99gcZR0B1rpa33a30yG) published by Raissi et al. \n",
    "\n",
    "In this notebook we will solve the steady 1D heat transfer in a composite bar. You can refer to the [Modulus User Documentation](https://docs.nvidia.com/deeplearning/modulus/index.html) for more examples on solving different types of PDEs using Modulus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "- How to use Modulus to simulate physics problems using PINNs\n",
    "    - How to write your own PDEs and formulate the different losses\n",
    "    - How to use the Constructive Solid Geometry (CSG) module\n",
    "- How to use Modulus to solve a parameterized PDEs \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "Our aim is to obtain the temperature distribution inside the bar that is made up of two materials with different thermal conductivity. The geometry and the problem specification of the problem can be seen below:\n",
    "\n",
    "<img src=\"diffusion_bar_geometry.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "The composite bar extends from $x=0$ to $x=2$. The bar has material of conductivity $D_1=10$ from $x=0$ to $x=1$ and $D_2=0.1$ from $x=1$ to $x=2$. Both the ends of the bar, $x=0$ and $x=2$ are maintained at a constant temperature of $0$ and $100$ respectively. For simplicity of modeling, we will treat the composite bar as two separate bars, bar 1 and bar 2, whose ends are joined together. We will treat the temperatures in bar 1 as $U_1$ and the temperature in bar 2 as $U_2$.\n",
    "\n",
    "The equations and boundary conditions governing the problem can be mathematically expressed as...\n",
    "\n",
    "One dimensional diffusion of temperature in bar 1 and 2:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{d}{dx}\\left( D_1\\frac{dU_1}{dx} \\right) = 0, && \\text{when } 0<x<1 \\\\\n",
    "\\frac{d}{dx}\\left( D_2\\frac{dU_2}{dx} \\right) = 0, && \\text{when } 1<x<2 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Flux and temperature continuity at interface $(x=1)$\n",
    "$$\n",
    "\\begin{align}\n",
    "D_1\\frac{dU_1}{dx} = D_2\\frac{dU_2}{dx}, && \\text{when } x=1 \\\\\n",
    "U_1 = U_2, && \\text{when } x=1 \\\\\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Setup\n",
    "\n",
    "Now that we have our problem defined, let's take a look at the code required to solve it using Modulus. Modulus has a variety of helper functions/APIs that will help us to set up the problem with ease. Modulus has APIs to model geometry in a parameterized fashion using the Constructive Solid Geometry (CSG) module, write-up the required equations in a user-friendly symbolic format, and comes with several advanced neural network architectures to choose for more complicated problems. \n",
    "\n",
    "Now let's start the problem by importing the required libraries and packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style='color:Red'> Note!  </span>\n",
    "\n",
    "In this notebook we will describe the contents of the [`diffusion_bar.py`](../../source_code/diffusion_1d/diffusion_bar.py) script. Hence, the majority of the code blocks in this notebook are only representative. You will have to update the main [`diffusion_bar.py`](../../source_code/diffusion_1d/diffusion_bar.py) script to make any changes or for hyperparameter tuning. If you prefer a more interactive, Jupyter way of setting things up, please refer the [Anatomy of a Modulus Project](../introduction/Modulus_Anatomy.ipynb) for information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import numpy as np\n",
    "from sympy import Symbol, Eq, Function, Number\n",
    "\n",
    "import modulus\n",
    "from modulus.hydra import to_absolute_path, ModulusConfig, instantiate_arch\n",
    "from modulus.solver import Solver\n",
    "from modulus.domain import Domain\n",
    "from modulus.geometry.primitives_1d import Line1D\n",
    "from modulus.domain.constraint import (\n",
    "    PointwiseBoundaryConstraint,\n",
    "    PointwiseInteriorConstraint,\n",
    ")\n",
    "from modulus.domain.validator import PointwiseValidator\n",
    "from modulus.domain.monitor import PointwiseMonitor\n",
    "from modulus.key import Key\n",
    "from modulus.node import Node\n",
    "from modulus.eq.pde import PDE\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from v22.03 Modulus supports APIs for solving data-driven problems where the data is available on grid/mesh as well as the PINN problems where point clouds are used for problem formulation. In this section, since we will be solving the 1D diffusion problem using the PINN approach, we will use the CSG module to set up the geometry and point clouds. The `Solver` class trains and evaluates Modulus' neural network solver. The `Domain` class is used to add constraints, monitors, validators, etc. to the problem.\n",
    "\n",
    "The `geometry` module contains pre-defined geometries that one can use to define the problem. We will describe each of them in detail as we move forward in the code. For more detailed information on all the different modules, we recommended you to refer the [Modulus API Documentation](https://docs.nvidia.com/deeplearning/modulus/api_source/api_index.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Geometry\n",
    "\n",
    "In this problem, we will create a 1D geometry using the [`Line1D`](https://docs.nvidia.com/deeplearning/modulus/api/modulus.geometry.html#modulus.geometry.primitives_1d.Line1D) class from the `geometry` module. The module also contains several 2D and 3D shapes like rectangle, circle, triangle, cuboids, sphere, torus, cones, tetrahedrons, etc. We will define the 1D line object using two end-points. For the composite bar, we will create two separate bars as defined in the problem statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# params for domain\n",
    "L1 = Line1D(0,1)\n",
    "L2 = Line1D(1,2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define the properties for the problem which will later be used while making the equations, boundary conditions, etc. For this particular problem, we can find the temperature at the interface analytically, and we will use that to form validation data to compare our neural network results against."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "D1 = 1e1\n",
    "D2 = 1e-1\n",
    "\n",
    "Tc = 100\n",
    "Ta = 0\n",
    "Tb = (Tc + (D1 / D2) * Ta) / (1 + (D1 / D2))\n",
    "\n",
    "print(Ta)\n",
    "print(Tb)\n",
    "print(Tc)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Differential Equations for the Problem\n",
    "\n",
    "The `PDE` class allows us to write the equations symbolically in SymPy. This allows us to quickly write our equations in the most natural way possible. The SymPy equations are converted to PyTorch expressions in the back-end and can also be printed to ensure correct implementation.\n",
    "\n",
    "Modulus also comes with several common PDEs pre-defined for us to choose from. Some of the PDEs that are already available in the PDEs module are: Navier-Stokes, Linear Elasticity, Advection Diffusion, Wave Equations, etc.\n",
    "\n",
    "Let's create the PDE to define the diffusion equation. We will define the equation in its most generic, transient 3D form and then have an argument `dim` that can reduce it to lower dimensional forms. \n",
    "$$\\frac{\\partial T}{\\partial t}= \\nabla\\cdot \\left( D \\nabla T \\right) + Q$$\n",
    "\n",
    "Let's start defining the equation by inheriting from the `PDE` class. We will create the initialization method for this class that defines the equation(s) of interest. We will be defining the diffusion equation using the source(`Q`), diffusivity(`D`), and symbol for diffusion(`T`). If `D` or `Q` is given as a string we will convert it to functional form. This will allow us to solve problems with spatially/temporally varying properties. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Diffusion(PDE):\n",
    "    name = \"Diffusion\"\n",
    "\n",
    "    def __init__(self, T=\"T\", D=\"D\", Q=0, dim=3, time=True):\n",
    "        # set params\n",
    "        self.T = T\n",
    "        self.dim = dim\n",
    "        self.time = time\n",
    "\n",
    "        # coordinates\n",
    "        x, y, z = Symbol(\"x\"), Symbol(\"y\"), Symbol(\"z\")\n",
    "\n",
    "        # time\n",
    "        t = Symbol(\"t\")\n",
    "\n",
    "        # make input variables\n",
    "        input_variables = {\"x\": x, \"y\": y, \"z\": z, \"t\": t}\n",
    "        if self.dim == 1:\n",
    "            input_variables.pop(\"y\")\n",
    "            input_variables.pop(\"z\")\n",
    "        elif self.dim == 2:\n",
    "            input_variables.pop(\"z\")\n",
    "        if not self.time:\n",
    "            input_variables.pop(\"t\")\n",
    "\n",
    "        # Temperature\n",
    "        assert type(T) == str, \"T needs to be string\"\n",
    "        T = Function(T)(*input_variables)\n",
    "\n",
    "        # Diffusivity\n",
    "        if type(D) is str:\n",
    "            D = Function(D)(*input_variables)\n",
    "        elif type(D) in [float, int]:\n",
    "            D = Number(D)\n",
    "\n",
    "        # Source\n",
    "        if type(Q) is str:\n",
    "            Q = Function(Q)(*input_variables)\n",
    "        elif type(Q) in [float, int]:\n",
    "            Q = Number(Q)\n",
    "\n",
    "        # set equations\n",
    "        self.equations = {}\n",
    "        self.equations[\"diffusion_\" + self.T] = (\n",
    "            T.diff(t)\n",
    "            - (D * T.diff(x)).diff(x)\n",
    "            - (D * T.diff(y)).diff(y)\n",
    "            - (D * T.diff(z)).diff(z)\n",
    "            - Q\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review the class. First we defined the input variables $x, y, z$ and $t$ with SymPy symbols. Then we defined the functions for $T$, $D$ and $Q$ that are dependent on the input variables $(x, y, z, t)$. Using these we can write out our simple equation $T_t = \\nabla \\cdot (D \\nabla T) + Q$. We store this equation in the class by adding it to the dictionary of `equations`.\n",
    "\n",
    "Note that we moved all the terms of the PDE either to LHS or RHS. This way, while using the equations in the constraints, we\n",
    "can assign a custom source function to the `’diffusion_T’` key instead of 0 to add more source terms to our PDE.\n",
    "\n",
    "Great! We just wrote our own PDE in Modulus. Once you have understood the process to code a simple PDE, you can easily extend the procedure for different PDEs. You can also bundle multiple PDEs together in the same file by adding new keys to the equations dictionary. Below we show the code for the interface boundary condition where we need to maintain the field (dirichlet) and flux (neumann) continuity. More examples of coding your own PDE can be found in the [Modulus User Documentation](https://docs.nvidia.com/deeplearning/modulus/text/foundational/1d_wave_equation.html).\n",
    "\n",
    "**Note :** The field continuity condition is needed because we are solving for two different temperatures in the two bars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class DiffusionInterface(PDE):\n",
    "    name = \"DiffusionInterface\"\n",
    "\n",
    "    def __init__(self, T_1, T_2, D_1, D_2, dim=3, time=True):\n",
    "        # set params\n",
    "        self.T_1 = T_1\n",
    "        self.T_2 = T_2\n",
    "        self.dim = dim\n",
    "        self.time = time\n",
    "\n",
    "        # coordinates\n",
    "        x, y, z = Symbol(\"x\"), Symbol(\"y\"), Symbol(\"z\")\n",
    "        normal_x, normal_y, normal_z = (\n",
    "            Symbol(\"normal_x\"),\n",
    "            Symbol(\"normal_y\"),\n",
    "            Symbol(\"normal_z\"),\n",
    "        )\n",
    "\n",
    "        # time\n",
    "        t = Symbol(\"t\")\n",
    "\n",
    "        # make input variables\n",
    "        input_variables = {\"x\": x, \"y\": y, \"z\": z, \"t\": t}\n",
    "        if self.dim == 1:\n",
    "            input_variables.pop(\"y\")\n",
    "            input_variables.pop(\"z\")\n",
    "        elif self.dim == 2:\n",
    "            input_variables.pop(\"z\")\n",
    "        if not self.time:\n",
    "            input_variables.pop(\"t\")\n",
    "\n",
    "        # Diffusivity\n",
    "        if type(D_1) is str:\n",
    "            D_1 = Function(D_1)(*input_variables)\n",
    "        elif type(D_1) in [float, int]:\n",
    "            D_1 = Number(D_1)\n",
    "        if type(D_2) is str:\n",
    "            D_2 = Function(D_2)(*input_variables)\n",
    "        elif type(D_2) in [float, int]:\n",
    "            D_2 = Number(D_2)\n",
    "\n",
    "        # variables to match the boundary conditions (example Temperature)\n",
    "        T_1 = Function(T_1)(*input_variables)\n",
    "        T_2 = Function(T_2)(*input_variables)\n",
    "\n",
    "        # set equations\n",
    "        self.equations = {}\n",
    "        self.equations[\"diffusion_interface_dirichlet_\" + self.T_1 + \"_\" + self.T_2] = (\n",
    "            T_1 - T_2\n",
    "        )\n",
    "        flux_1 = D_1 * (\n",
    "            normal_x * T_1.diff(x) + normal_y * T_1.diff(y) + normal_z * T_1.diff(z)\n",
    "        )\n",
    "        flux_2 = D_2 * (\n",
    "            normal_x * T_2.diff(x) + normal_y * T_2.diff(y) + normal_z * T_2.diff(z)\n",
    "        )\n",
    "        self.equations[\"diffusion_interface_neumann_\" + self.T_1 + \"_\" + self.T_2] = (\n",
    "            flux_1 - flux_2\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating PDE and Neural Network Nodes\n",
    "\n",
    "The default [`FullyConnectedArch`](https://docs.nvidia.com/deeplearning/modulus/api/modulus.models.html#module-modulus.models.fully_connected) (selected by setting `cfg.arch.fully_connected` in the `cfg` argument of the `instantiate_arch()` function) can be used to create the neural network for the problem. The default `FullyConnectedArch` represents a 6 layer MLP (multi-layer perceptron) architecture with each layer containing 512 nodes and uses swish (SiLU) as the activation function. All these parameters are user configurable, and can be configured using Hydra config files. Once all the PDEs and architectures are defined, we can create a list of nodes to pass to different constraints we want to satisfy for this problem (i.e. equations residuals, boundary conditions, etc.).\n",
    "\n",
    "Here we create a single list that contains all the computational nodes for the problem. When this list is passed to the `nodes` argument of each class, Modulus will automatically unroll/evaluate the appropriate nodes based on the variables specified in the `outvar` directory. \n",
    "\n",
    "We will define all the code for the problem in the `run` function as shown below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@modulus.main(config_path=\"conf\", config_name=\"config\")\n",
    "def run(cfg: ModulusConfig) -> None:\n",
    "    # make list of nodes to unroll graph on\n",
    "    diff_u1 = Diffusion(T=\"u_1\", D=D1, dim=1, time=False)\n",
    "    diff_u2 = Diffusion(T=\"u_2\", D=D2, dim=1, time=False)\n",
    "    diff_in = DiffusionInterface(\"u_1\", \"u_2\", D1, D2, dim=1, time=False)\n",
    "\n",
    "    diff_net_u_1 = instantiate_arch(\n",
    "        input_keys=[Key(\"x\")],\n",
    "        output_keys=[Key(\"u_1\")],\n",
    "        cfg=cfg.arch.fully_connected,\n",
    "    )\n",
    "    diff_net_u_2 = instantiate_arch(\n",
    "        input_keys=[Key(\"x\")],\n",
    "        output_keys=[Key(\"u_2\")],\n",
    "        cfg=cfg.arch.fully_connected,\n",
    "    )\n",
    "\n",
    "    nodes = (\n",
    "        diff_u1.make_nodes()\n",
    "        + diff_u2.make_nodes()\n",
    "        + diff_in.make_nodes()\n",
    "        + [diff_net_u_1.make_node(name=\"u1_network\", jit=cfg.jit)]\n",
    "        + [diff_net_u_2.make_node(name=\"u2_network\", jit=cfg.jit)]\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Quick Note on Hydra to Configure Modulus\n",
    "\n",
    "At the heart of using Modulus are Hydra config files. The one for this example is found in the code shown below. Using Hydra allows a highly customizable but user-friendly method for configuring the majority of Modulus’ features. More information can be found in [Modulus Configuration](https://docs.nvidia.com/deeplearning/modulus/text/features/configuration.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "defaults :\n",
    "  - modulus_default\n",
    "  - arch:\n",
    "      - fully_connected\n",
    "  - scheduler: tf_exponential_lr\n",
    "  - optimizer: adam\n",
    "  - loss: sum\n",
    "  - _self_\n",
    "\n",
    "arch:\n",
    "    fully_connected:\n",
    "        layer_size: 256\n",
    "\n",
    "save_filetypes : \"vtk,npz\"\n",
    "\n",
    "scheduler:\n",
    "  decay_rate: 0.95\n",
    "  decay_steps: 100\n",
    "\n",
    "optimizer: \n",
    "  lr : 1e-4\n",
    "\n",
    "training:\n",
    "  rec_results_freq: 1000\n",
    "  max_steps : 5000\n",
    "\n",
    "batch_size:\n",
    "  rhs: 2\n",
    "  lhs: 2\n",
    "  interface: 2\n",
    "  interior_u1: 200\n",
    "  interior_u2: 200\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Domain: Assigning the Boundary and PDE Constraints\n",
    "\n",
    "As described earlier, we need to define a domain for training our neural network. The `Domain` and the configs are passed as inputs when using the `Solver` class. Apart from constraints, you can add various other utilities to the `Domain` such as monitors, validation data, points to do inference on, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make domain add constraints to the solver\n",
    "    domain = Domain()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s look into adding constraints to this domain which will drive the neural network optimization. To re-iterate, for this physics-driven problem, these constraints are the boundary conditions and equation residuals. The goal is to satisfy the boundary conditions exactly, and ideally have the PDE residuals to go 0. These constraints can be specified within Modulus using classes like `PointwiseBoundaryConstraint` and `PointwiseInteriorConstraint`. For more information, please refer the [Introductory Notebook](../introduction/Introductory_Notebook.ipynb).\n",
    "\n",
    "**Boundary constraints:** A boundary can be sampled using the `PointwiseBoundaryConstraint` class. This will sample the entire boundary of the geometry we specify in the `geometry` argument, in this case, both the endpoints of the 1D line. A particular boundary of the geometry can be sub-sampled by using a particular criterion using the `criteria` parameter. For example, to sample the left end of `L1`, `criteria` is set to `Eq(x, 0)`. \n",
    "\n",
    "The desired values for the boundary condition are listed as a dictionary in the `outvar` argument. For this problem, we have `'u_1':0` at $x=0$ and `'u_2':100` at $x=2$. At $x=1$, we have the interface condition `'diffusion_interface_dirichlet_u_1_u_2':0` and `'diffusion_interface_neumann_u_1_u_2':0` that we defined earlier (i.e. $U_1=U_2$ and $D_1\\frac{dU_1}{dx}=D_2\\frac{dU_2}{dx}$). These dictionaries are then used when unrolling the computational graph (specified using the `nodes` argument) for training.  \n",
    "\n",
    "The number of points to sample on each boundary are specified using the `batch_size` parameter. \n",
    "\n",
    "**Equations to solve:** The diffusion PDE we defined is enforced on all the points in the\n",
    "interior of both the bars, `L1` and `L2`. We will use `PointwiseInteriorConstraint` class to sample points in the interior of the geometry. Again, the appropriate geometry is specified in the `geometry` argument: the equations to solve are specified as a dictionary input to the `outvar` argument. These dictionaries are then used when unrolling the computational graph (specified using the `nodes` argument) for training.\n",
    "\n",
    "For this problem we have the `'diffusion_u_1':0` and `'diffusion_u_2':0` for bars `L1` and `L2` respectively. The parameter `bounds` determines the range for sampling the values for variables $x$ and $y$. The optional `lambda` parameter can be used to determine the weights for different losses. In this problem, we weight the loss on each point equally, and hence it is not used.\n",
    "\n",
    "**Note:** Here we specified the same list that contains all the possible nodes in the computational graph. This is done purely from simplicity standpoint to avoid creating separate list of nodes for each constraint. Modulus automatically select the appropriate nodes to compute based on the keys specified in the `outvar`, so the unused nodes are not evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # sympy variables\n",
    "    x = Symbol(\"x\")\n",
    "\n",
    "    # right hand side (x = 2) Pt c\n",
    "    rhs = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L2,\n",
    "        outvar={\"u_2\": Tc},\n",
    "        batch_size=cfg.batch_size.rhs,\n",
    "        criteria=Eq(x, 2),\n",
    "    )\n",
    "    domain.add_constraint(rhs, \"right_hand_side\")\n",
    "\n",
    "    # left hand side (x = 0) Pt a\n",
    "    lhs = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L1,\n",
    "        outvar={\"u_1\": Ta},\n",
    "        batch_size=cfg.batch_size.lhs,\n",
    "        criteria=Eq(x, 0),\n",
    "    )\n",
    "    domain.add_constraint(lhs, \"left_hand_side\")\n",
    "\n",
    "    # interface 1-2\n",
    "    interface = PointwiseBoundaryConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L1,\n",
    "        outvar={\n",
    "            \"diffusion_interface_dirichlet_u_1_u_2\": 0,\n",
    "            \"diffusion_interface_neumann_u_1_u_2\": 0,\n",
    "        },\n",
    "        batch_size=cfg.batch_size.interface,\n",
    "        criteria=Eq(x, 1),\n",
    "    )\n",
    "    domain.add_constraint(interface, \"interface\")\n",
    "\n",
    "    # interior 1\n",
    "    interior_u1 = PointwiseInteriorConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L1,\n",
    "        outvar={\"diffusion_u_1\": 0},\n",
    "        bounds={x: (0, 1)},\n",
    "        batch_size=cfg.batch_size.interior_u1,\n",
    "    )\n",
    "    domain.add_constraint(interior_u1, \"interior_u1\")\n",
    "\n",
    "    # interior 2\n",
    "    interior_u2 = PointwiseInteriorConstraint(\n",
    "        nodes=nodes,\n",
    "        geometry=L2,\n",
    "        outvar={\"diffusion_u_2\": 0},\n",
    "        bounds={x: (1, 2)},\n",
    "        batch_size=cfg.batch_size.interior_u2,\n",
    "    )\n",
    "    domain.add_constraint(interior_u2, \"interior_u2\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Validation Data\n",
    "\n",
    "For this 1D bar problem where the conductivity is constant in each bar, the temperature varies linearly with position inside the solid. The analytical solution can then be given as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "U_1 = xT_b + (1-x)T_a, && \\text{when } 0 \\leq x \\leq 1 \\\\\n",
    "U_2 = (x-1)T_c + (2-x)T_b, && \\text{when } 1 \\leq x \\leq 2 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where, \n",
    "$$\n",
    "\\begin{align}\n",
    "T_a = U_1|_{x=0}, && T_c = U_2|_{x=2}, && \\frac{\\left(T_c + \\left( D_1/D_2 \\right)T_a \\right)}{1+ \\left( D_1/D_2 \\right)}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Now let's create the validators. The validation data is added to the domain using the [`PointwiseValidator`](https://docs.nvidia.com/deeplearning/modulus/api/modulus.domain.validator.html#modulus.domain.validator.continuous.PointwiseValidator) class. We use NumPy to solve for the `u_1` and `u_2` based on the analytical expressions we showed above. The dictionary of generated NumPy arrays (`invar_numpy` and `outvar_numpy`) for input and output variables and the appropriate nodes are used in the definition of the constructor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # validation data\n",
    "    x = np.expand_dims(np.linspace(0, 1, 100), axis=-1)\n",
    "    u_1 = x * Tb + (1 - x) * Ta\n",
    "    invar_numpy = {\"x\": x}\n",
    "    outvar_numpy = {\"u_1\": u_1}\n",
    "    val = PointwiseValidator(nodes=nodes, invar=invar_numpy, true_outvar=outvar_numpy)\n",
    "    domain.add_validator(val, name=\"Val1\")\n",
    "\n",
    "    # make validation data line 2\n",
    "    x = np.expand_dims(np.linspace(1, 2, 100), axis=-1)\n",
    "    u_2 = (x - 1) * Tc + (2 - x) * Tb\n",
    "    invar_numpy = {\"x\": x}\n",
    "    outvar_numpy = {\"u_2\": u_2}\n",
    "    val = PointwiseValidator(nodes=nodes, invar=invar_numpy, true_outvar=outvar_numpy)\n",
    "    domain.add_validator(val, name=\"Val2\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Monitors \n",
    "\n",
    "Modulus allows you to monitor desired quantities in Tensorboard as the simulation progresses and\n",
    "assess the convergence. A [`PointwiseMonitor`](https://docs.nvidia.com/deeplearning/modulus/api/modulus.domain.validator.html#modulus.domain.validator.continuous.PointwiseValidator) can be used to create such a feature. Examples of such quantities can be point values of variables, surface averages, volume averages or any derived quantities that can be formed using the variables being solved.\n",
    "\n",
    "The variables are available as PyTorch tensors. We can perform tensor operations available in PyTorch to compute any desired derived quantity of our choice.\n",
    "\n",
    "In the code below, we create monitors for flux at the interface. The variable `u_1__x` represents the derivative of `u_1` in the x-direction (two underscores (`__`) and the variable (`x`)). The same notation is used while handling other derivatives using the Modulus library. (e.g. a neumann boundary condition of $\\frac{dU_1}{dx}=0$ can be assigned as `'u_1__x':0` in the train domain for solving the same problem with an adiabatic/fixed flux boundary condition). \n",
    "\n",
    "The points to sample can be selected similarly as we did for specifying some of the interior constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make monitors\n",
    "    invar_numpy = {\"x\": [[1.0]]}\n",
    "    monitor = PointwiseMonitor(\n",
    "        invar_numpy,\n",
    "        output_names=[\"u_1__x\"],\n",
    "        metrics={\"flux_u1\": lambda var: torch.mean(var[\"u_1__x\"])},\n",
    "        nodes=nodes,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "    domain.add_monitor(monitor)\n",
    "\n",
    "    monitor = PointwiseMonitor(\n",
    "        invar_numpy,\n",
    "        output_names=[\"u_2__x\"],\n",
    "        metrics={\"flux_u2\": lambda var: torch.mean(var[\"u_2__x\"])},\n",
    "        nodes=nodes,\n",
    "        requires_grad=True,\n",
    "    )\n",
    "    domain.add_monitor(monitor)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting Everything Together: Solver and Training\n",
    "\n",
    "We can create a solver by using the domain we just created along with the other configurations that define the optimizer choices, settings (i.e. conf) using Modulus’ `Solver` class. The solver can then be executed using the `solve` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    # make solver\n",
    "    slv = Solver(cfg, domain)\n",
    "\n",
    "    # start solver\n",
    "    slv.solve()\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have just completed the file setup for the problem using Modulus. We are now ready to solve the PDEs using neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "Before we start training, we can make use of Tensorboard for visualizing the loss values and convergence of several monitors we just created. Execute the following cell to start Tensorboard. After training begins you can use the refresh icon in Tensorboard to view the visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir outputs/diffusion_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the Tensorboard up and running for monitoring purposes, execute the `diffusion_bar.py` script inside the Jupyter cell. This example is already saved for you and the code block below executes that script [`diffusion_bar.py`](../../source_code/diffusion_1d/diffusion_bar.py). You are encouraged to open the script and go through the code once before executing. You can also edit the parameters in the [`config.yaml`](../../source_code/diffusion_1d/conf/) file of the model and see its effect on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../../source_code/diffusion_1d/diffusion_bar.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Solution\n",
    "\n",
    "Modulus saves the data in several formats (including .vtp, .vtk and .npz). The .npz arrays can be plotted to visualize the output of the simulation. The .npz files that are created are found in the `outputs/` directory.\n",
    "\n",
    "Now let's plot the temperature along the bar for the analytical and the neural network solution. A sample script to plot the results is shown below. If the training is complete, you should get the results like shown below. As we can see, our neural network solution and the analytical solution match almost exactly for this diffusion problem. \n",
    "\n",
    "<img src=\"image_diffusion_problem_bootcamp.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "!{sys.executable} -m pip install ipympl\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "network_dir = \"./outputs/diffusion_bar/validators/\"\n",
    "data_1 = np.load(network_dir + \"Val1.npz\", allow_pickle=True)\n",
    "data_2 = np.load(network_dir + \"Val2.npz\", allow_pickle=True)\n",
    "data_1 = np.atleast_1d(data_1.f.arr_0)[0]\n",
    "data_2 = np.atleast_1d(data_2.f.arr_0)[0]\n",
    "\n",
    "plt.plot(data_1[\"x\"][:, 0], data_1[\"pred_u_1\"][:, 0], \"--\", label=\"u_1_pred\")\n",
    "plt.plot(data_2[\"x\"][:, 0], data_2[\"pred_u_2\"][:, 0], \"--\", label=\"u_2_pred\")\n",
    "plt.plot(data_1[\"x\"][:, 0], data_1[\"true_u_1\"][:, 0], label=\"u_1_true\")\n",
    "plt.plot(data_2[\"x\"][:, 0], data_2[\"true_u_2\"][:, 0], label=\"u_2_true\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"image_diffusion_problem_bootcamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "display(Image(filename='./image_diffusion_problem_bootcamp.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook we will train the same 1D diffusion problem, but this time by parameterizing the conductivity of the first bar.\n",
    "\n",
    "Please continue to [the next notebook](Diffusion_Problem_Parameterized.ipynb)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
