{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameterized and Inverse Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will turn our attention to a key advantage of neural network solvers over traditional numerical methods, namely, the ability to solve parameterized geometries and inverse problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterized Problems\n",
    "\n",
    "One important advantage of a neural network solver over traditional numerical methods is its ability to solve parameterized geometries. To illustrate this concept we solve a parameterized version of the above problem. Suppose we want to know how the solution to this equation changes as we move the position on the boundary condition $u(l)=0$. We can parameterize this position with a variable $l \\in [1,2]$ and our equation now has the form:\n",
    "\n",
    "\\begin{equation} \\label{1d_equation2}\n",
    "    \\mathbf{P} : \\left\\{\\begin{matrix}\n",
    "\\frac{\\delta^2 u}{\\delta x^2}(x) = f(x), \\\\ \n",
    "\\\\\n",
    "u(0) = u(l) = 0,\n",
    "\\end{matrix}\\right.\n",
    "\\end{equation}\n",
    "\n",
    "To solve this parameterized problem we can have the neural network take $l$ as input, $u_{net}(x,l)$. The losses then take the form:\n",
    "\n",
    "\\begin{equation}\n",
    "  L_{residual} = \\int_1^2 \\int_0^l \\left( \\frac{\\delta^2 u_{net}}{\\delta x^2}(x,l) - f(x) \\right)^2 dx dl \\approx \\left(\\int_1^2 \\int^l_0 dxdl\\right) \\frac{1}{N} \\sum^{N}_{i=0} \\left(\\frac{\\delta^2 u_{net}}{\\delta x^2}(x_i, l_i) - f(x_i)\\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "  L_{BC} = \\int_1^2 (u_{net}(0,l))^2 + (u_{net}(l,l) dl \\approx \\left(\\int_1^2 dl\\right) \\frac{1}{N} \\sum^{N}_{i=0} (u_{net}(0, l_i))^2 + (u_{net}(l_i, l_i))^2\n",
    "\\end{equation}\n",
    "\n",
    "In the figure below we see the solution to the differential equation for various $l$ values after optimizing the network on this loss. While this example problem is overly simplistic, the ability to solve parameterized geometries presents significant industrial value. Instead of performing a single simulation we can solve multiple designs at the same time and for reduced computational cost. More examples of this can be found in the [Modulus User Documentation](https://docs.nvidia.com/deeplearning/modulus/index.html).\n",
    "\n",
    "<img src=\"every_parabola.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Problems \n",
    "\n",
    "Another useful application of a neural network solver is solving inverse problems. In an inverse problem, we start with a set of observations and then use those observations to calculate the causal factors that produced them. To illustrate how to solve inverse problems with a neural network solver, we give the example of inverting out the source term $f(x)$ from the same equation from the above problem. Suppose we are given the solution $u_{true}(x)$ at 100 random points between 0 and 1, and we want to determine the $f(x)$ that is causing it. We can do this by making two neural networks $u_{net}(x)$ and $f_{net}(x)$ to approximate both $u(x)$ and $f(x)$. These networks are then optimized to minimize the following losses:\n",
    "\n",
    "\\begin{equation}\n",
    "  L_{residual} \\approx \\left(\\int^1_0 dx\\right) \\frac{1}{N} \\sum^{N}_{i=0} \\left(\\frac{\\delta^2 u_{net}}{\\delta x^2}(x_i, l_i) - f_{net}(x_i)\\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "  L_{data} = \\frac{1}{100} \\sum^{100}_{i=0} (u_{net}(x_i) - u_{true}(x_i))^2\n",
    "\\end{equation}\n",
    "\n",
    "Using the function $u_{true}(x)=\\frac{1}{48} (8 x (-1 + x^2) - (3 sin(4 \\pi x))/\\pi^2)$ the solution for $f(x)$ is $x + sin(4 \\pi x)$. We solve this problem and compare the results in the figures below:\n",
    "\n",
    "<figure>\n",
    "    <img src=\"inverse_parabola.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "    <figcaption>Comparison of true solution for $f(x)$ and the function approximated by the NN.</figcaption>\n",
    "</figure>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"inverse_parabola_2.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "    <figcaption>Comparison of $u_{net}(x)$ and the train points from $u_{true}$.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More examples of solving an inverse problem can be found in the [Modulus User Documentation](https://docs.nvidia.com/deeplearning/modulus/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now covered the brief theory behind the PINNs and also saw the essential components to solve a problem using Modulus. Let's cover these applications in detail over the next couple of notebooks where we will focus on solving the parameterized, transient and inverse cases. Then we will dive into the data-driven training using Modulus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. Raissi, Maziar, Paris Perdikaris, and George Em Karniadakis. “Physics informed deep learning (part i): Data-driven solutions of nonlinear partial differential equations.” arXiv preprint arXiv:1711.10561 (2017).\n",
    "2. Sun, Luning, et al. “Surrogate modeling for fluid flows based on physics-constrained deep learning without simulation data.” Computer Methods in Applied Mechanics and Engineering 361 (2020): 112732."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will dive in to the Modulus APIs in detail and give you a head start in solving your own Partial Differential Equations (PDEs) using neural networks.\n",
    "\n",
    "Please continue to [the next notebook](../diffusion_1d/Diffusion_Problem_Notebook.ipynb)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
