{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-driven PBRPK for Theranostics\n",
    "Author: Binesh Sadanandan\n",
    "Date created: 2024/02\n",
    "Description: In this study, we are trying to model a data driven PBPK model based on https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10803696/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install required python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T02:36:39.386035Z",
     "start_time": "2024-02-05T02:36:39.320224Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC,SVR\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, DeltaYStopper\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.width', 3000)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from Drive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_files(folder_path):\n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    dataframes = []\n",
    "    print(f'Found {len(csv_files)} csv files in {folder_path}')\n",
    "\n",
    "    for file in csv_files:\n",
    "        #print(f'Processing {file}......')\n",
    "        try:\n",
    "         df = pd.read_csv(os.path.join(folder_path, file))\n",
    "         df['FileName'] = file\n",
    "         df.columns = [col.replace('UnknownCompartment_', '') for col in df.columns]\n",
    "         dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f'Error processing {file} : {e}')\n",
    "            continue\n",
    "    df_all = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "    for col in df_all.columns:\n",
    "        if col != 'FileName':\n",
    "            df_all[col] = df_all[col].astype(float)\n",
    "    \n",
    "    return df_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/tbin/Library/CloudStorage/GoogleDrive-contact@bineshkumar.me/My Drive/Colab Notebooks/UBC_PSMA_Model_Simulator_Data/SimDataCSVs'\n",
    "# Uncomment the below line to read all the files \n",
    "df_all=process_csv_files(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in df_all.columns if 'bser'  in col or 'parameter' in col or ('Vein' in col and 'Alb' not in col) or 'Time' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['FileName','Time',\n",
    " 'Vein_species_Hot',\n",
    " 'Vein_species_Cold',\n",
    " 'parameter_lambdaPhys',\n",
    " 'parameter_numberPerNanomole',\n",
    " 'observable_repeatInterval',\n",
    " 'observable_repeatdose',\n",
    " 'parameter_Tumor1VolumeCoeff',\n",
    " 'parameter_bodyWeight',\n",
    " 'parameter_bodySurfaceArea',\n",
    " 'observable_Tumor1_TotalHot',\n",
    " 'observable_Tumor2_TotalHot',\n",
    " 'observable_TumorTotalHot',\n",
    " 'observable_KidneyTotalHot',\n",
    " 'observable_SGTotalHot',\n",
    " 'observable_LiverTotalHot',\n",
    " 'observable_ProstateTotalHot',\n",
    " 'observable_SpleenTotalHot',\n",
    " 'observable_RedMarrowTotalHot',\n",
    " 'observable_BoneTotalHot',\n",
    " 'observable_TIA_TumorTotal',\n",
    " 'observable_TIA_Kidney',\n",
    " 'observable_TIA_SG',\n",
    " 'observable_TIA_Liver',\n",
    " 'observable_TIA_Spleen',\n",
    " 'observable_TIA_RedMarrow',\n",
    " 'observable_HotStuffBlood',\n",
    " 'observable_BloodTIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all.to_csv(folder_path.replace('SimDataCSVs', 'df_all_sim.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(folder_path.replace('SimDataCSVs', 'df_all_sim.csv'))\n",
    "df_all=df_all[df_all['Time']<11520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df_by_unique_values(df, column_name, num_unique):\n",
    "    unique_values = df[column_name].unique()\n",
    "    sampled_values = np.random.choice(unique_values, size=num_unique, replace=False)\n",
    "    filtered_df = df[df[column_name].isin(sampled_values)]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(filename,combined_df=df_all):\n",
    "    filtered_df = combined_df[combined_df['FileName'] == filename]\n",
    "    plt.figure(figsize=(8, 7))\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(10, 7), sharex=True) \n",
    "    updated_observables = ['Vein_species_Hot', 'Vein_species_Cold']\n",
    "\n",
    "   \n",
    "    for ax, observable in zip(axs, updated_observables):\n",
    "        ax.plot(filtered_df['Time'], filtered_df[observable], label=observable)\n",
    "        ax.set_title(observable)\n",
    "        ax.set_ylabel('Value')\n",
    "\n",
    "   \n",
    "    axs[-1].set_xlabel('Time (minutes)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_data('SimDataResults_497.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [col for col in df_all.columns if  col not in ['Unnamed: 0', 'FileName', 'Time']]\n",
    "df_all['DateTime'] = pd.to_datetime('2020-01-01') + pd.to_timedelta(df_all['Time'], unit='m')\n",
    "df_all.set_index('DateTime', inplace=True)\n",
    "df_transf=pd.DataFrame()\n",
    "unique_files = df_all['FileName'].unique()\n",
    "for file in unique_files:\n",
    "    sample_file_data = df_all[df_all['FileName'] == file][feature_columns]\n",
    "    daily_aggregated_data = sample_file_data.resample('1440T').max()\n",
    "    daily_aggregated_data['FileName']=file\n",
    "    daily_aggregated_data.reset_index(drop=True, inplace=True)\n",
    "    df_transf = pd.concat([df_transf, daily_aggregated_data])\n",
    "\n",
    "df_transf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start From Home if Restarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T02:40:12.616682Z",
     "start_time": "2024-02-05T02:40:09.591939Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_transf.to_csv(folder_path.replace('SimDataCSVs', 'df_trans_sim.csv'))\n",
    "folder_path = '/Users/tbin/Library/CloudStorage/GoogleDrive-contact@bineshkumar.me/My Drive/Colab Notebooks/UBC_PSMA_Model_Simulator_Data/SimDataCSVs'\n",
    "df_transf=pd.read_csv(folder_path.replace('SimDataCSVs','df_trans_sim.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T02:40:16.535370Z",
     "start_time": "2024-02-05T02:40:16.512780Z"
    }
   },
   "outputs": [],
   "source": [
    "df_transf['TIAOARTotal']=df_transf['observable_TIA_Kidney'] + df_transf['observable_TIA_SG'] + df_transf['observable_TIA_Liver'] + df_transf['observable_TIA_Spleen'] + df_transf['observable_TIA_RedMarrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T02:40:20.498050Z",
     "start_time": "2024-02-05T02:40:20.487678Z"
    }
   },
   "outputs": [],
   "source": [
    "numerical_features = ['parameter_Tumor1VolumeCoeff', 'parameter_bodySurfaceArea', 'parameter_bodyWeight', 'Vein_species_Cold', 'parameter_RepeatTimeInterval', 'parameter_lambdaPhys', 'Vein_species_Hot', 'parameter_numberPerNanomole', 'parameter_RepeatCount']\n",
    "target_col='observable_TumorTotalHot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T02:40:23.147272Z",
     "start_time": "2024-02-05T02:40:23.132451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "parameter_Tumor1VolumeCoeff     1036\nparameter_bodySurfaceArea       1036\nparameter_bodyWeight            1036\nVein_species_Cold               1036\nparameter_RepeatTimeInterval    1036\nparameter_lambdaPhys            1036\nVein_species_Hot                1036\nparameter_numberPerNanomole     1036\nparameter_RepeatCount           1036\nobservable_TumorTotalHot        1036\ndtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transf[numerical_features + [target_col]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T02:40:29.062083Z",
     "start_time": "2024-02-05T02:40:29.044576Z"
    }
   },
   "outputs": [],
   "source": [
    "df_transf = df_transf[~df_transf[target_col].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T02:40:37.246778Z",
     "start_time": "2024-02-05T02:40:37.235818Z"
    }
   },
   "outputs": [],
   "source": [
    "X=df_transf[numerical_features]\n",
    "y=df_transf[target_col]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T02:40:38.784096Z",
     "start_time": "2024-02-05T02:40:38.782343Z"
    }
   },
   "outputs": [],
   "source": [
    "models_to_run = [Ridge(), SVR(), RandomForestRegressor(), xgb.XGBRegressor(), lgb.LGBMRegressor()]\n",
    "\n",
    "model_parm_search = [\n",
    "    { # Ridge\n",
    "     'alpha': Real(1e-5, 100, prior='log-uniform'),\n",
    "     \"solver\": Categorical(['svd', 'cholesky', 'lsqr', 'sag']),\n",
    "     'fit_intercept': Categorical([True, False]),\n",
    "    },\n",
    "    \n",
    "    { # SVR\n",
    "     'C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
    "     \"kernel\": Categorical(['linear', 'poly', 'rbf', 'sigmoid']),\n",
    "     'gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
    "     \"epsilon\": Real(0, 1),\n",
    "    },\n",
    "\n",
    "{ # RandomForestRegressor\n",
    " 'max_depth': Integer(3, 12),\n",
    " 'n_estimators': Integer(100, 1000),\n",
    " 'max_features': Categorical(['sqrt', 'log2', None]),  # Adjusted here\n",
    "},\n",
    "\n",
    "    { # XGBRegressor\n",
    "     'learning_rate': Real(1e-4, 1.0, 'log-uniform'),\n",
    "     'colsample_bytree': Real(0.1, 0.9),\n",
    "     'n_estimators': Integer(100, 1000),\n",
    "     'reg_alpha': Real(1, 1.5, 'log-uniform'),\n",
    "     'reg_lambda': Real(1, 1.5, 'log-uniform'),\n",
    "    },\n",
    "\n",
    "    { # LGBMRegressor\n",
    "     'learning_rate': Real(1e-4, 1.0, 'log-uniform'),\n",
    "     'n_estimators': Integer(100, 1000),\n",
    "     'max_depth': Integer(3, 12),\n",
    "     'reg_alpha': Real(1, 1.5, 'log-uniform'),\n",
    "     'reg_lambda': Real(1, 1.5, 'log-uniform'),\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-02-05T02:40:58.406184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Ridge(alpha=100.0, solver='cholesky')\n",
      "\n",
      "The 5-CV rmse Score was: -0.020945197976233666\n",
      "With a standard deviation of: 0.0008436017266379932\n",
      "Test rmse socre: 0.02\n",
      "\n",
      "The 5-CV R2 Score was: 0.3361050257964767\n",
      "With a standard deviation of: 0.015510468333860999\n",
      "Test R2 Score : 0.35\n",
      "Train R2 Score : 0.34\n",
      "Model:  SVR(C=59.548319327653964, epsilon=0.08612990629669139,\n",
      "    gamma=0.0010148863931733528, kernel='sigmoid')\n",
      "\n",
      "The 5-CV rmse Score was: -0.08363660196833793\n",
      "With a standard deviation of: 0.00029219041653640254\n",
      "Test rmse socre: 0.08\n",
      "\n",
      "The 5-CV R2 Score was: -9.648045210034782\n",
      "With a standard deviation of: 1.0094616779071421\n",
      "Test R2 Score : -10.41\n",
      "Train R2 Score : -9.55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "np.int=int\n",
    "for i, model in enumerate(models_to_run):\n",
    "   # build the Bayesian search model\n",
    "   bs = BayesSearchCV(\n",
    "       estimator=model,\n",
    "       search_spaces=model_parm_search[i],\n",
    "       cv = cv,\n",
    "       n_iter = 20,\n",
    "       n_jobs = -1, \n",
    "       scoring = \"r2\",\n",
    "       #return_train_score=True,\n",
    "       random_state = 2\n",
    "   )\n",
    "\n",
    "   bs.fit(X_train, y_train)\n",
    "   \n",
    "   model    = bs.best_estimator_\n",
    "   test_preds = model.predict(X_test)\n",
    "   train_preds = model.predict(X_train)\n",
    "\n",
    "    \n",
    "   r2_kfolds = cross_val_score(model, X_train, y_train, cv = cv, n_jobs=-1, scoring='r2')\n",
    "   rmse_kfolds = cross_val_score(model, X_train, y_train, cv = cv, n_jobs=-1, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "   print(\"Model: \", model)\n",
    "   print('\\nThe 5-CV rmse Score was:', rmse_kfolds.mean()) \n",
    "   print('With a standard deviation of:', rmse_kfolds.std())\n",
    "   print('Test rmse socre: %.2f' %mse(y_test, test_preds, squared=False))\n",
    "\n",
    "   print('\\nThe 5-CV R2 Score was:', r2_kfolds.mean()) \n",
    "   print('With a standard deviation of:', r2_kfolds.std())\n",
    "   print(\"Test R2 Score : %.2f\" %r2_score(y_test, test_preds))\n",
    "   print(\"Train R2 Score : %.2f\" %r2_score(y_train, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "explore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
