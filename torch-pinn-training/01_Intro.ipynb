{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision.models import resnet18,ResNet18_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.array([[1,2],[3,4],[5,6],[7,8]])\n",
    "d_ten=torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time with cpu (10000): 0.002279000000000142\n",
      "Total time with cpu (100000000): 0.5439260000000001\n",
      "Total time with gpu (10000): 0.08924899999999991\n",
      "Total time with gpu (100000000): 0.010088000000000097\n"
     ]
    }
   ],
   "source": [
    "from time import process_time\n",
    "import torch\n",
    "\n",
    "def testgpu():\n",
    "    if torch.backends.mps.is_available():\n",
    "        mps_device = torch.device(\"mps\")\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n1, device=mps_device)\n",
    "    y = x + torch.rand(n1, device=mps_device)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with gpu ({n1}): {t1-t0}\")\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n2, device=mps_device)\n",
    "    y = x + torch.rand(n2, device=mps_device)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with gpu ({n2}): {t1-t0}\")\n",
    "\n",
    "def testcpu():\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n1)\n",
    "    y = x + torch.rand(n1)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with cpu ({n1}): {t1-t0}\")\n",
    "    t0 = process_time()\n",
    "    x = torch.ones(n2)\n",
    "    y = x + torch.rand(n2)\n",
    "    t1 = process_time()\n",
    "    print(f\"Total time with cpu ({n2}): {t1-t0}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    n1 = 10000\n",
    "    n2 = 100000000\n",
    "    testcpu()\n",
    "    testgpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/tbin/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model=resnet18(weights=ResNet18_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(1,3,64,64)\n",
    "labels=torch.rand(1,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicitons=model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6253, -0.6692, -0.6953, -1.6911, -0.6454, -0.3179, -0.6382,  0.3785,\n",
       "          0.2900, -1.0577, -1.0340, -0.7162, -0.3011, -0.8780, -1.1103, -0.7048,\n",
       "         -0.5595, -0.0714, -0.5304, -0.4918, -1.6844, -0.6956, -1.3387,  0.2803,\n",
       "         -0.8612, -1.2923, -0.9007, -1.1646, -0.7655, -0.5322, -0.8551, -0.7584,\n",
       "         -0.4943, -0.6541, -0.4007, -0.4882,  0.6437, -0.8981, -0.1897,  0.0326,\n",
       "         -0.5988, -0.8059, -1.1475, -0.3342, -0.4475, -0.2851, -0.6626, -0.1923,\n",
       "         -1.4100, -1.0383, -0.6004,  0.4320, -0.2323, -0.5803, -0.0493, -1.0998,\n",
       "         -0.2082, -1.4172, -0.5152, -0.3786,  0.9110,  0.1381,  0.0291,  0.4190,\n",
       "         -0.5097, -0.1400, -0.1539, -0.2255, -0.7299, -1.2140, -1.5847,  0.0387,\n",
       "         -1.3675, -0.2381, -1.1131, -1.2433,  0.0491, -0.6537,  0.4184,  0.1088,\n",
       "         -0.7693, -1.8072, -0.0865, -0.7718, -0.4942, -0.1273, -0.0113,  0.2935,\n",
       "         -0.2893, -0.8612, -1.2412, -1.0524, -1.8331, -0.3786, -0.0056, -2.2428,\n",
       "         -0.4513, -0.4791, -1.5173, -0.2380, -1.0360, -1.2219, -1.1083, -0.3305,\n",
       "         -0.2123, -0.6226, -0.5858, -1.3519, -1.1044, -1.4694, -1.0727, -0.7328,\n",
       "          0.9879,  0.3125,  0.4315, -1.1067, -0.8180, -0.3361,  0.5428, -0.5376,\n",
       "         -0.9703, -0.2059,  0.0569,  0.0110,  0.8133, -0.2367,  0.4945, -1.3465,\n",
       "         -1.2063, -1.3418, -1.4332, -1.4373, -0.9984, -1.1906, -0.7803, -1.2395,\n",
       "         -0.8288, -1.1943, -1.4911, -1.7296, -1.7735, -1.7613, -2.3335, -1.7662,\n",
       "         -0.6593, -0.4573, -1.0541, -1.9746, -1.3304, -1.2616,  0.2891,  1.3997,\n",
       "         -1.1422, -0.4614,  0.0186,  0.2106, -0.4838, -0.3188,  0.0566,  0.1471,\n",
       "          0.5052,  0.5570,  0.0653,  0.6364,  0.0534, -0.2351, -0.3707, -0.6183,\n",
       "          0.5267, -0.3975, -0.2242,  0.8111,  0.3215,  0.3443, -0.0090, -0.8270,\n",
       "          0.0151, -0.0849,  0.5718,  0.5621,  0.4965, -0.0298,  0.5308,  0.1874,\n",
       "          0.7410,  0.6740,  0.5025,  0.2251,  0.0578,  0.4675, -0.4824,  0.3550,\n",
       "          0.4824,  0.5705, -0.7923,  0.5849,  0.1826,  0.0738,  0.4078,  0.7097,\n",
       "          0.0686,  0.0903,  0.7076,  0.6439,  0.1157,  0.2749, -0.1224,  0.3962,\n",
       "          1.1939,  0.5183, -0.0990,  0.2213,  0.1133, -0.2088, -0.2046,  0.2809,\n",
       "         -0.1628,  0.2310, -0.5389,  0.4523,  0.1418, -0.2680, -0.1133,  0.6996,\n",
       "          0.3265,  0.5928,  0.0830,  0.7872, -0.4965, -0.1199,  0.0269,  0.4803,\n",
       "          0.3184, -0.0569,  0.7767,  0.8427,  0.3245,  0.2787,  0.8263, -0.3084,\n",
       "          0.5462, -0.1994,  0.3529,  0.2830, -0.3239,  0.0981,  0.4925, -0.0196,\n",
       "          0.6067,  0.0778,  0.4118,  0.4865, -0.7876,  0.4808,  0.8621, -0.6257,\n",
       "          0.3013,  0.1464, -0.2031, -0.0084, -0.2986, -0.5769, -0.2961,  0.3049,\n",
       "          0.6746,  0.5886,  0.0389,  0.3038, -0.1681, -0.5981, -1.0116, -1.1983,\n",
       "         -0.6926,  0.4678, -1.3031, -1.1466, -1.4268, -0.9749, -1.3949, -0.5603,\n",
       "         -0.5262,  0.7166,  0.6637,  0.1901,  0.3789,  0.8544, -0.2802, -0.3802,\n",
       "         -0.8562, -1.7692, -1.1555, -1.3607, -0.4031, -1.1041, -1.2444, -1.1663,\n",
       "         -1.0548, -1.6244, -0.5216, -0.4631, -2.0623, -0.8065, -0.5409, -0.2437,\n",
       "         -1.2855, -0.9060,  0.1228, -0.9550, -1.4386, -0.5819,  0.4106, -0.5434,\n",
       "         -0.5614,  0.3641,  0.5993, -0.6566, -0.9483, -1.2824, -1.1601, -0.6931,\n",
       "         -1.4955, -1.0329, -1.2008, -1.5819, -1.5609, -1.7679, -1.2489, -0.0244,\n",
       "         -0.0784, -0.6994, -0.0243, -0.2896,  0.2884,  0.2787, -0.3827, -0.8405,\n",
       "         -1.8674,  0.3150,  0.8891, -1.2946, -0.5329,  0.6288, -0.5883, -1.4716,\n",
       "         -0.8509,  0.5047, -1.0228, -1.7170, -0.3585, -1.6134, -1.2064, -2.4729,\n",
       "         -1.3777, -0.8314, -0.9789,  0.3275,  1.0354,  0.0369,  0.3894,  0.2647,\n",
       "         -0.2099,  0.6274, -0.0922,  0.1852, -0.4106, -0.5718, -1.0695, -0.4513,\n",
       "         -0.9263, -0.7061, -0.6302, -0.4141, -0.4459, -0.0335, -0.2250, -1.0434,\n",
       "         -1.1301,  0.2078, -0.4294, -0.5743,  0.1662, -0.4253, -0.3425, -0.5201,\n",
       "         -0.8119, -0.4942, -1.1255, -1.3013, -1.1016, -0.2709,  0.5829, -0.0574,\n",
       "         -1.5307, -1.8162, -0.2000,  0.4017, -1.2202, -0.7768,  0.2562,  0.0974,\n",
       "         -0.9459,  0.7758,  0.2172, -2.1036, -1.9278, -0.6729, -0.3549, -0.2647,\n",
       "         -0.1775,  1.2745, -0.3335,  0.1322,  2.1162,  0.9758,  0.5833,  1.1898,\n",
       "         -0.3626,  0.3912,  0.4512,  1.0878,  0.7229,  1.4994, -0.3540,  0.4021,\n",
       "          0.3368, -0.8688, -0.0513,  1.4724,  1.5144,  0.4258, -0.8531,  0.0523,\n",
       "          0.3154,  0.5307,  0.4406,  0.9456, -0.4176, -0.2952,  0.4410,  0.5880,\n",
       "          0.7476,  0.6715,  0.1757, -0.5205, -0.3690,  0.0365,  0.3780,  1.3669,\n",
       "          0.9759, -0.6740, -0.3400,  0.3921,  0.7141, -0.2169, -0.2532,  0.5592,\n",
       "          1.7568,  1.4573, -0.2545,  0.7469, -0.6419,  0.6781,  1.7282,  2.2752,\n",
       "          1.0246, -0.0842, -0.9883, -0.0985,  0.0778,  1.6999,  1.0080,  0.5677,\n",
       "          0.1261,  1.1001, -0.0675,  0.0834,  0.2082,  0.6098,  0.9240,  0.4391,\n",
       "          0.2324,  0.3045,  0.4357, -0.9208, -1.4120, -0.0610, -0.4004,  1.3284,\n",
       "          1.7778,  1.1833,  0.5537,  0.9672,  0.6036, -1.1778,  1.3885, -0.9920,\n",
       "          0.0988, -0.5655, -0.1759,  1.3192, -1.6781,  0.6459,  1.4355,  0.6363,\n",
       "          1.0754,  1.1179,  1.1365,  0.8572,  0.3555,  0.2538, -1.1028, -1.0519,\n",
       "          0.8458,  0.2921,  1.1761,  1.7795,  0.4696,  0.3779,  1.4030,  0.8130,\n",
       "         -0.7456,  0.0671,  0.9693,  1.9647,  0.3663, -0.7033, -0.2505, -0.5150,\n",
       "          0.5045,  0.1872,  1.2037,  0.3985,  0.1528, -1.1095,  0.4864, -0.4892,\n",
       "         -0.4057, -0.7337,  0.0355,  1.4356, -1.1793,  1.7206,  1.2064,  0.5928,\n",
       "          0.4848,  0.9674,  0.8044, -1.9574, -1.2503, -0.0544, -0.4690,  0.1607,\n",
       "          0.6650,  0.0342, -1.3437, -0.7512,  0.4677,  0.6683,  1.2733,  0.9352,\n",
       "          0.1110, -0.0316,  1.1351,  0.2778, -1.2726, -0.6480,  0.0386,  0.9319,\n",
       "          0.7596, -0.5285,  0.9900,  0.3694,  0.8737, -0.8832,  0.5404, -0.1662,\n",
       "         -0.9833,  1.0094,  0.1860,  0.1105,  0.3963, -0.3538,  0.6915,  0.6631,\n",
       "          1.0691,  0.9358, -0.4381,  1.8463,  1.3086,  1.2092, -0.6424,  0.5372,\n",
       "         -0.7734,  0.8159,  0.4781, -0.4698,  1.2380, -0.1411, -0.4939,  0.8263,\n",
       "          2.4212, -0.2145, -0.2041, -0.6805,  0.5865,  0.1678,  1.3397, -0.6323,\n",
       "          0.6842, -0.2690,  0.9550,  0.7690, -0.3553,  0.7525,  0.2501,  0.4287,\n",
       "          1.3650,  0.6830,  1.8370,  0.9875,  1.0160,  0.7886,  0.2390,  0.5583,\n",
       "          0.0989, -1.2471,  1.2839, -0.2541, -1.1601,  0.4008,  0.2127,  1.0798,\n",
       "          0.7570,  1.0644, -0.1082,  0.2469,  1.4566,  0.9802,  0.7624, -0.0043,\n",
       "         -1.9498,  1.1739, -0.0512,  1.5561,  0.8288, -0.8239,  0.6169,  0.3964,\n",
       "         -0.6599, -1.7147,  1.1995,  0.1478,  0.8130,  0.7766, -0.0810,  0.8691,\n",
       "          0.1043,  0.2861,  0.1180,  0.3604, -0.0689, -1.2015, -0.0622, -0.8578,\n",
       "          1.0680,  0.0452,  1.1905,  0.3586, -0.5708, -0.3541,  0.2117, -0.2330,\n",
       "         -0.2557,  0.6913,  1.6850, -0.7844,  1.7153,  1.1305,  1.0876,  0.1963,\n",
       "          0.6139,  0.5809, -0.6950,  0.5043,  0.9027, -1.2850, -0.2865, -1.1045,\n",
       "         -0.1202, -1.0101, -0.8262,  0.9591,  1.1006,  0.7049, -0.8328,  1.0805,\n",
       "          1.8531, -0.0434, -0.3427,  0.8623,  1.7876, -0.0639, -0.1679,  0.4682,\n",
       "          0.9646, -0.2544, -0.3454,  0.5879,  0.8007,  0.3038,  1.1910,  1.0190,\n",
       "         -0.0244, -0.3806,  0.4924, -0.3732,  0.5417, -0.8762, -0.2673,  0.7699,\n",
       "          0.0203,  0.3753,  1.2465,  0.4246, -0.6028,  1.2394, -0.5516,  0.0579,\n",
       "          1.5803, -0.6354,  0.0910,  2.1731, -0.7142,  2.2889, -1.4695,  0.1349,\n",
       "         -0.1865,  0.7217,  1.1656,  0.0382,  1.2463, -0.0071,  0.4134,  0.5762,\n",
       "          0.9093,  0.0562,  0.0515,  0.7109,  0.8762,  1.7329,  0.4147, -0.0028,\n",
       "          0.2663,  0.4914,  0.8797, -0.4763,  1.2261,  0.1331,  1.6537, -0.0353,\n",
       "          0.1677,  0.8337,  0.5191,  0.7885,  1.4053,  1.0735,  0.2456,  0.4687,\n",
       "         -0.1275,  1.4116,  0.2839,  0.3483,  1.6367,  0.5638,  1.0245,  0.2938,\n",
       "          0.4913,  0.7861,  1.4083, -0.7689, -0.8781, -0.7396,  1.1232,  0.9552,\n",
       "          1.6804,  0.5015,  0.7696,  1.2295,  0.2872,  0.0941,  0.6985,  1.1434,\n",
       "          1.8210,  1.0809,  0.3617,  0.2818,  1.1836,  0.6709, -0.9014,  0.7807,\n",
       "         -0.8183,  0.1146, -1.1015, -1.3148,  1.4860,  1.0478,  0.5623,  0.5474,\n",
       "          1.3804, -0.1392, -0.6143,  1.0231, -0.1004,  1.6996, -1.0601, -0.2573,\n",
       "          0.5892, -1.1542,  1.8145,  0.5505, -1.5609, -0.9112,  0.4672,  0.8280,\n",
       "          1.2103, -1.0619,  0.5480,  1.0093,  1.1164, -0.4249,  1.0986,  0.3517,\n",
       "         -0.9364, -1.0551,  0.3094,  0.6454,  1.8254,  1.7220,  1.0423, -0.6010,\n",
       "          1.7315,  0.5622,  0.3660,  0.6513,  0.8158,  1.7940,  0.9349, -0.2076,\n",
       "          0.6276,  0.8974,  1.4514,  1.5039,  2.1141, -0.3488, -0.3439,  0.8710,\n",
       "         -0.4543, -0.2056, -0.6036,  0.9814,  0.2413,  1.3673,  1.0934,  0.0791,\n",
       "         -0.3568,  0.5673, -0.1356, -0.2732,  1.2008, -0.3372,  0.9541, -1.1206,\n",
       "          1.3557, -1.1255, -2.1074,  0.4166,  1.4787, -0.1376, -0.3523,  1.7729,\n",
       "          1.1506, -0.3292,  1.4731,  1.3677,  0.1857,  0.2671, -0.2061, -0.2193,\n",
       "         -1.0725,  0.3375, -0.4435, -0.0148,  0.8819,  0.1918, -0.4940, -0.5631,\n",
       "          1.0586,  0.7138,  2.1674,  1.9899, -1.0092, -0.5753,  1.7177,  1.0474,\n",
       "          1.0089,  0.3112, -0.1228,  1.3875, -1.0747,  0.9286,  1.3023,  1.2749,\n",
       "          0.6867, -0.5130, -1.8365, -0.6249,  0.2402,  0.2952,  0.4213,  0.4103,\n",
       "          0.0451,  1.0111, -0.8313,  0.4019, -0.4856, -1.1449, -1.2343, -0.5928,\n",
       "         -0.1304,  1.4894, -0.0596,  0.0804,  0.6232, -1.7830, -0.0600, -0.7892,\n",
       "          0.3184,  0.2528, -0.0096, -0.1622, -0.4628, -0.8358, -0.4913,  0.0429,\n",
       "         -0.5089, -0.6968, -1.2014,  0.5821,  0.7445, -0.3975,  0.0333, -0.5838,\n",
       "         -0.7618,  0.1087,  0.7031, -0.1756, -0.3345, -0.6687,  0.0444, -1.0718,\n",
       "          0.2515,  0.4399, -0.6892, -1.0374, -1.3845, -0.6324,  0.5476, -0.4523,\n",
       "          0.8581, -0.1012, -0.2149,  1.0631, -0.4298, -0.3665, -2.0144,  0.9623,\n",
       "         -1.7646,  0.2697,  0.0357, -0.8053, -0.8667,  0.0115,  0.5576, -0.4570,\n",
       "         -1.0807, -1.2973, -2.4532,  1.4533, -0.1040, -1.0390, -0.3742, -1.2856,\n",
       "         -0.8893, -2.0021, -0.6460, -0.5354,  0.2998, -0.3828,  1.4792,  0.8739]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicitons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_thera_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
